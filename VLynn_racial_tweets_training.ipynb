{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label classification of racial tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6481, 5)\n",
      "\n",
      "Index(['tweetidg', 'tweet', 'positive', 'negative', 'neutral'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetidg</th>\n",
       "      <th>tweet</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>588687492888551424g</td>\n",
       "      <td>i am the type of nigga tryna get rich</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>592553981601304576g</td>\n",
       "      <td>sheblasiannn smuckers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>717371522956984320g</td>\n",
       "      <td>proteinwisdom we even make japanese cars and e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>590292541125328898g</td>\n",
       "      <td>i wanted to see my nigga when i went back home...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592522044480225282g</td>\n",
       "      <td>wth stevo is that a nigga</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetidg                                              tweet  \\\n",
       "0  588687492888551424g              i am the type of nigga tryna get rich   \n",
       "1  592553981601304576g                              sheblasiannn smuckers   \n",
       "2  717371522956984320g  proteinwisdom we even make japanese cars and e...   \n",
       "3  590292541125328898g  i wanted to see my nigga when i went back home...   \n",
       "4  592522044480225282g                          wth stevo is that a nigga   \n",
       "\n",
       "   positive  negative  neutral  \n",
       "0       0.0       0.0      1.0  \n",
       "1       0.0       0.0      1.0  \n",
       "2       0.0       0.0      1.0  \n",
       "3       0.0       1.0      0.0  \n",
       "4       0.0       0.0      1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#Read in csv of cleaned data\n",
    "df = pd.read_csv('df_tweets.csv', index_col=0)\n",
    "\n",
    "#Create training set\n",
    "\n",
    "df_train = df[df['tweet'].notnull()]\n",
    "print(df_train.shape)\n",
    "print('')\n",
    "print(df_train.columns)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a table to examine the distribution of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category  Number_of_Tweets    priors\n",
      "0  positive            1642.0  0.253356\n",
      "1  negative            1977.0  0.305046\n",
      "2   neutral            2862.0  0.441599\n",
      "\n",
      "Total number of labels:   6481.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_sparse = df_train.drop(['tweetidg', 'tweet'], axis=1)\n",
    "\n",
    "counts = []\n",
    "priors = []\n",
    "categories = list(df_sparse.columns.values)\n",
    "for i in categories:\n",
    "    numarts = df_sparse[i].sum()\n",
    "    counts.append((i, numarts))\n",
    "\n",
    "df_stats = pd.DataFrame(counts, columns=['Category', 'Number_of_Tweets'])\n",
    "total = df_stats.Number_of_Tweets.sum()\n",
    "\n",
    "df_stats['priors'] = df_stats['Number_of_Tweets']/total\n",
    "\n",
    "print(df_stats)\n",
    "print('')\n",
    "print('Total number of labels:  ', total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweetidg', 'tweet', 'positive', 'negative', 'neutral'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure all entries in df_matrix['text'] are strings\n",
    "df_train['tweet'] = df_train['tweet'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Function for positive labels\n",
    "def make_x(df, vectorizer=None):\n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer(stop_words='english',binary=False,max_df=50, ngram_range=(1, 1),\n",
    "                                     min_df=1,strip_accents='unicode',max_features=200)\n",
    "    X = vectorizer.fit_transform(df_train.tweet)\n",
    "    \n",
    "    #X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    return type(X)\n",
    "#Call the function: X\n",
    "make_x(df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#Function for negative labels\n",
    "def make_xy_neg(df, vectorizer=None):\n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer(stop_words='english',binary=False,max_df=25,\n",
    "                                     min_df=1,strip_accents='unicode',max_features=100)\n",
    "    X = vectorizer.fit_transform(df_train.tweet)\n",
    "    X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    y = df_train['negative'].values.astype(np.int)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#Function for neutral labels\n",
    "def make_xy_neut(df, vectorizer=None):\n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer(stop_words='english',binary=False,max_df=25,\n",
    "                                     min_df=1,strip_accents='unicode',max_features=100)\n",
    "    X = vectorizer.fit_transform(df_train.tweet)\n",
    "    X = X.tocsc()  # some versions of sklearn return COO format\n",
    "    y = df_train['neutral'].values.astype(np.int)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize the data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english',binary=False,max_df=50, ngram_range=(1, 1),\n",
    "                                     min_df=1,strip_accents='unicode',max_features=200)\n",
    "\n",
    "featurizer = TfidfVectorizer(stop_words='english',binary=False,max_df=50,min_df=1)\n",
    "X = featurizer.fit_transform(df_train.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive - training set accuracy:  0.8115079365079365\n",
      "Positive - test set accuracy:  0.744987146529563 \n",
      "\n",
      "Negative - training set accuracy:  0.8968253968253969\n",
      "Negative - test set accuracy:  0.7491002570694087 \n",
      "\n",
      "Neutral - training set accuracy:  0.9126984126984127\n",
      "Neutral - test set accuracy:  0.6519280205655527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clf_NB = MultinomialNB()\n",
    "\n",
    "#Positive scores\n",
    "yp = df_train['positive'].values.astype(np.int)\n",
    "X_trainp, X_testp, y_trainp, y_testp = train_test_split(X, yp, test_size=0.30, random_state=42)\n",
    "\n",
    "clf_NB.fit(X_trainp,y_trainp)\n",
    "\n",
    "train_accuracy_pos =clf_NB.score(X_trainp,y_trainp)\n",
    "test_accuracy_pos = clf_NB.score(X_testp, y_testp)\n",
    "print(\"Positive - training set accuracy: \", train_accuracy_pos)\n",
    "print(\"Positive - test set accuracy: \", test_accuracy_pos, '\\n')\n",
    "        \n",
    "#Negative scores\n",
    "yn = df_train['negative'].values.astype(np.int)\n",
    "X_trainn, X_testn, y_trainn, y_testn = train_test_split(X, yn, test_size=0.30, random_state=42)\n",
    "\n",
    "clf_NB.fit(X_trainn,y_trainn)\n",
    "\n",
    "train_accuracy_neg = clf_NB.score(X_trainn, y_trainn)\n",
    "test_accuracy_neg = clf_NB.score(X_testn, y_testn)\n",
    "print(\"Negative - training set accuracy: \", train_accuracy_neg)\n",
    "print(\"Negative - test set accuracy: \", test_accuracy_neg, '\\n')\n",
    "        \n",
    "#Neutral scores\n",
    "yne = df_train['neutral'].values.astype(np.int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, yne, test_size=0.30, random_state=42)\n",
    "\n",
    "clf_NB.fit(X_train,y_train)\n",
    "\n",
    "train_accuracy_neut = clf_NB.score(X_train, y_train)\n",
    "test_accuracy_neut = clf_NB.score(X_test, y_test)\n",
    "print(\"Neutral - training set accuracy: \", train_accuracy_neut)\n",
    "print(\"Neutral - test set accuracy: \", test_accuracy_neut)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is looking good! But accuracy can be deceiving. High accuracy scores can still happen if your model detects many true negatives, but no true positives! Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Precision_NB</th>\n",
       "      <th>Recall_NB</th>\n",
       "      <th>F1_NB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>[[4822, 17], [1599, 43]]</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.026188</td>\n",
       "      <td>0.050529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>[[4314, 190], [1384, 593]]</td>\n",
       "      <td>0.757344</td>\n",
       "      <td>0.299949</td>\n",
       "      <td>0.429710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[[3207, 412], [1886, 976]]</td>\n",
       "      <td>0.703170</td>\n",
       "      <td>0.341020</td>\n",
       "      <td>0.459294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categories            Confusion Matrix  Precision_NB  Recall_NB     F1_NB\n",
       "0   positive    [[4822, 17], [1599, 43]]      0.716667   0.026188  0.050529\n",
       "1   negative  [[4314, 190], [1384, 593]]      0.757344   0.299949  0.429710\n",
       "2    neutral  [[3207, 412], [1886, 976]]      0.703170   0.341020  0.459294"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "#Prediciton with NB\n",
    "conmatrxNB = []\n",
    "precisionNB = []\n",
    "recallNB = []\n",
    "f1NB = []\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "\n",
    "    y_train_pred = cross_val_predict(clf_NB, X, df_train[category], cv=5)\n",
    "    \n",
    "    cmNB = confusion_matrix(df_train[category], y_train_pred)\n",
    "    conmatrxNB.append(cmNB)\n",
    "    precNB = precision_score(df_train[category], y_train_pred)    \n",
    "    precisionNB.append(precNB)\n",
    "    recNB = recall_score(df_train[category], y_train_pred)\n",
    "    recallNB.append(recNB)\n",
    "    fNB = f1_score(df_train[category], y_train_pred)\n",
    "    f1NB.append(fNB)\n",
    "\n",
    "    \n",
    "dictNB = {'Categories':categories, 'Confusion Matrix':conmatrxNB, 'Precision_NB':precisionNB, 'Recall_NB':recallNB, 'F1_NB':f1NB}\n",
    "df_NB = pd.DataFrame(dictNB) \n",
    "#df_NB.to_csv('Results_NB_tweets.csv')\n",
    "\n",
    "df_NB_tweets = df_NB[df_NB['Precision_NB'] >= 0]\n",
    " \n",
    "df_NB_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I expected, high accuracy doesn't always mean high precision or recall. We can see that these are lower. I will run the other models first, then tune parameters on the one showing the most promise for this data. Note that for the neutral label, accuracy was lower than precision. For this study, we want to decrease the probability of a Type 2 error - a false positive where we say there is an effect but there is not. Precision is the best score to tune because it is a measure of how sure we are that a label is a true label (true positive) if our algorithm classifies it as such. After running the other two classifiers, I will tune the hyper-parameters for the best performing classifier at these default settings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clf_SVC = OneVsRestClassifier(LinearSVC(), n_jobs=1)\n",
    "\n",
    "#Positive scores\n",
    "yp = df_train['positive'].values.astype(np.int)\n",
    "X_trainp, X_testp, y_trainp, y_testp = train_test_split(X, yp, test_size=0.30, random_state=42)\n",
    "\n",
    "clf_SVC.fit(X_trainp,y_trainp)\n",
    "\n",
    "train_accuracy_pos =clf_SVC.score(X_trainp,y_trainp)\n",
    "test_accuracy_pos = clf_SVC.score(X_testp, y_testp)\n",
    "print(\"Positive - training set accuracy: \", train_accuracy_pos)\n",
    "print(\"Positive - test set accuracy: \", test_accuracy_pos, '\\n')\n",
    "        \n",
    "#Negative scores\n",
    "yn = df_train['negative'].values.astype(np.int)\n",
    "X_trainn, X_testn, y_trainn, y_testn = train_test_split(X, yn, test_size=0.30, random_state=42)\n",
    "\n",
    "clf_SVC.fit(X_trainn,y_trainn)\n",
    "\n",
    "train_accuracy_neg = clf_SVC.score(X_trainn, y_trainn)\n",
    "test_accuracy_neg = clf_SVC.score(X_testn, y_testn)\n",
    "print(\"Negative - training set accuracy: \", train_accuracy_neg)\n",
    "print(\"Negative - test set accuracy: \", test_accuracy_neg, '\\n')\n",
    "        \n",
    "#Neutral scores\n",
    "yne = df_train['neutral'].values.astype(np.int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, yne, test_size=0.30, random_state=42)\n",
    "\n",
    "clf_SVC.fit(X_train,y_train)\n",
    "\n",
    "train_accuracy_neut = clf_SVC.score(X_train, y_train)\n",
    "test_accuracy_neut = clf_SVC.score(X_test, y_test)\n",
    "print(\"Neutral - training set accuracy: \", train_accuracy_neut)\n",
    "print(\"Neutral - test set accuracy: \", test_accuracy_neut)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Precision_SVC</th>\n",
       "      <th>Recall_SVC</th>\n",
       "      <th>F1_SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>[[4523, 316], [1313, 329]]</td>\n",
       "      <td>0.510078</td>\n",
       "      <td>0.200365</td>\n",
       "      <td>0.287713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>[[4045, 459], [1050, 927]]</td>\n",
       "      <td>0.668831</td>\n",
       "      <td>0.468892</td>\n",
       "      <td>0.551293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[[2801, 818], [1603, 1259]]</td>\n",
       "      <td>0.606163</td>\n",
       "      <td>0.439902</td>\n",
       "      <td>0.509820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categories             Confusion Matrix  Precision_SVC  Recall_SVC    F1_SVC\n",
       "0   positive   [[4523, 316], [1313, 329]]       0.510078    0.200365  0.287713\n",
       "1   negative   [[4045, 459], [1050, 927]]       0.668831    0.468892  0.551293\n",
       "2    neutral  [[2801, 818], [1603, 1259]]       0.606163    0.439902  0.509820"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_SVC = LinearSVC()\n",
    "\n",
    "\n",
    "#Prediciton with NB\n",
    "conmatrxSVC = []\n",
    "precisionSVC = []\n",
    "recallSVC = []\n",
    "f1SVC = []\n",
    "\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "\n",
    "    y_train_pred = cross_val_predict(clf_SVC, X, df_train[category], cv=5)\n",
    "    \n",
    "    cmSVC = confusion_matrix(df_train[category], y_train_pred)\n",
    "    conmatrxSVC.append(cmSVC)\n",
    "    precSVC = precision_score(df_train[category], y_train_pred)    \n",
    "    precisionSVC.append(precSVC)\n",
    "    recSVC = recall_score(df_train[category], y_train_pred)\n",
    "    recallSVC.append(recSVC)\n",
    "    fSVC = f1_score(df_train[category], y_train_pred)\n",
    "    f1SVC.append(fSVC)\n",
    "\n",
    "    \n",
    "dictSVC = {'Categories':categories, 'Confusion Matrix':conmatrxSVC, 'Precision_SVC':precisionSVC, \n",
    "           'Recall_SVC':recallSVC, 'F1_SVC':f1SVC}\n",
    "df_SVC = pd.DataFrame(dictSVC) \n",
    "#df_NB.to_csv('Results_NB_tweets.csv')\n",
    "\n",
    "df_SVC_tweets = df_SVC[df_SVC['Precision_SVC'] >= 0]\n",
    " \n",
    "df_SVC_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Precision_LR</th>\n",
       "      <th>Recall_LR</th>\n",
       "      <th>F1_LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>[[4827, 12], [1585, 57]]</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>0.066628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>[[4369, 135], [1482, 495]]</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.250379</td>\n",
       "      <td>0.379747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[[3226, 393], [1992, 870]]</td>\n",
       "      <td>0.688836</td>\n",
       "      <td>0.303983</td>\n",
       "      <td>0.421818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categories            Confusion Matrix  Precision_LR  Recall_LR     F1_LR\n",
       "0   positive    [[4827, 12], [1585, 57]]      0.826087   0.034714  0.066628\n",
       "1   negative  [[4369, 135], [1482, 495]]      0.785714   0.250379  0.379747\n",
       "2    neutral  [[3226, 393], [1992, 870]]      0.688836   0.303983  0.421818"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR = LogisticRegression()\n",
    "\n",
    "#vectorizer = CountVectorizer(stop_words='english',binary=False,max_df=50, ngram_range=(1, 1),\n",
    "                                     #min_df=1,strip_accents='unicode',max_features=200)\n",
    "#featurizer = TfidfVectorizer(stop_words='english',binary=False,max_df=50,min_df=1)\n",
    "#X = vectorizer.fit_transform(df_train.tweet)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Prediction with NB\n",
    "conmatrxLR = []\n",
    "precisionLR = []\n",
    "recallLR = []\n",
    "f1LR = []\n",
    "\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "\n",
    "    y_train_pred = cross_val_predict(clf_LR, X, df_train[category], cv=5)\n",
    "    \n",
    "    cmLR = confusion_matrix(df_train[category], y_train_pred)\n",
    "    conmatrxLR.append(cmLR)\n",
    "    precLR = precision_score(df_train[category], y_train_pred)    \n",
    "    precisionLR.append(precLR)\n",
    "    recLR = recall_score(df_train[category], y_train_pred)\n",
    "    recallLR.append(recLR)\n",
    "    fLR = f1_score(df_train[category], y_train_pred)\n",
    "    f1LR.append(fLR)\n",
    "\n",
    "    \n",
    "dictLR = {'Categories':categories, 'Confusion Matrix':conmatrxLR, 'Precision_LR':precisionLR,'Recall_LR':recallLR, 'F1_LR':f1LR}\n",
    "df_LR = pd.DataFrame(dictLR) \n",
    "#df_NB.to_csv('Results_NB_tweets.csv')\n",
    "\n",
    "df_LR_tweets = df_LR[df_LR['Precision_LR'] >= 0]\n",
    " \n",
    "df_LR_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Precision_RF</th>\n",
       "      <th>Recall_RF</th>\n",
       "      <th>F1_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>[[4528, 311], [1368, 274]]</td>\n",
       "      <td>0.468376</td>\n",
       "      <td>0.166870</td>\n",
       "      <td>0.246071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>[[4058, 446], [1175, 802]]</td>\n",
       "      <td>0.642628</td>\n",
       "      <td>0.405665</td>\n",
       "      <td>0.497364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[[2993, 626], [1858, 1004]]</td>\n",
       "      <td>0.615951</td>\n",
       "      <td>0.350804</td>\n",
       "      <td>0.447017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categories             Confusion Matrix  Precision_RF  Recall_RF     F1_RF\n",
       "0   positive   [[4528, 311], [1368, 274]]      0.468376   0.166870  0.246071\n",
       "1   negative   [[4058, 446], [1175, 802]]      0.642628   0.405665  0.497364\n",
       "2    neutral  [[2993, 626], [1858, 1004]]      0.615951   0.350804  0.447017"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_RF = RandomForestClassifier()\n",
    "\n",
    "\n",
    "#Prediciton with NB\n",
    "conmatrxRF = []\n",
    "precisionRF = []\n",
    "recallRF = []\n",
    "f1RF = []\n",
    "\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "\n",
    "    y_train_pred = cross_val_predict(clf_RF, X, df_train[category], cv=5)\n",
    "    \n",
    "    cmRF = confusion_matrix(df_train[category], y_train_pred)\n",
    "    conmatrxRF.append(cmRF)\n",
    "    precRF = precision_score(df_train[category], y_train_pred)    \n",
    "    precisionRF.append(precRF)\n",
    "    recRF = recall_score(df_train[category], y_train_pred)\n",
    "    recallRF.append(recRF)\n",
    "    fRF = f1_score(df_train[category], y_train_pred)\n",
    "    f1RF.append(fRF)\n",
    "\n",
    "    \n",
    "dictRF = {'Categories':categories, 'Confusion Matrix':conmatrxRF, 'Precision_RF':precisionRF, \n",
    "           'Recall_RF':recallRF, 'F1_RF':f1RF}\n",
    "df_RF = pd.DataFrame(dictRF) \n",
    "#df_NB.to_csv('Results_NB_tweets.csv')\n",
    "\n",
    "df_RF_tweets = df_RF[df_RF['Precision_RF'] >= 0]\n",
    " \n",
    "df_RF_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Precision_NB</th>\n",
       "      <th>Precision_SVC</th>\n",
       "      <th>Precision_LR</th>\n",
       "      <th>Precision_RF</th>\n",
       "      <th>Max_Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.510078</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.468376</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.757344</td>\n",
       "      <td>0.668831</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.642628</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.703170</td>\n",
       "      <td>0.606163</td>\n",
       "      <td>0.688836</td>\n",
       "      <td>0.615951</td>\n",
       "      <td>0.703170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categories  Precision_NB  Precision_SVC  Precision_LR  Precision_RF  \\\n",
       "0   positive      0.716667       0.510078      0.826087      0.468376   \n",
       "1   negative      0.757344       0.668831      0.785714      0.642628   \n",
       "2    neutral      0.703170       0.606163      0.688836      0.615951   \n",
       "\n",
       "   Max_Precision  \n",
       "0       0.826087  \n",
       "1       0.785714  \n",
       "2       0.703170  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = df_NB.Categories\n",
    "df_prec_NB  =df_NB.Precision_NB\n",
    "df_prec_SVC  = df_SVC.Precision_SVC\n",
    "df_prec_LR  = df_LR.Precision_LR\n",
    "df_prec_RF  = df_RF.Precision_RF\n",
    "\n",
    "df_prec1 = pd.DataFrame(columns = ['Categories', 'Precision_NB', 'Precision_SVC', \n",
    "                                   'Precision_LR', 'Precision_RF','Max_Precision'])\n",
    "df_prec1.Categories = df_NB.Categories\n",
    "df_prec1.Precision_NB = df_NB.Precision_NB\n",
    "df_prec1.Precision_SVC  = df_SVC.Precision_SVC\n",
    "df_prec1.Precision_LR  = df_LR.Precision_LR\n",
    "df_prec1.Precision_RF = df_RF.Precision_RF\n",
    "df_prec1.Max_Precision = df_prec1.max(axis=1)\n",
    "df_prec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Recall_NB</th>\n",
       "      <th>Recall_SVC</th>\n",
       "      <th>Recall_LR</th>\n",
       "      <th>Recall_RF</th>\n",
       "      <th>Max_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.026188</td>\n",
       "      <td>0.200365</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>0.166870</td>\n",
       "      <td>0.200365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.299949</td>\n",
       "      <td>0.468892</td>\n",
       "      <td>0.250379</td>\n",
       "      <td>0.405665</td>\n",
       "      <td>0.468892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.341020</td>\n",
       "      <td>0.439902</td>\n",
       "      <td>0.303983</td>\n",
       "      <td>0.350804</td>\n",
       "      <td>0.439902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categories  Recall_NB  Recall_SVC  Recall_LR  Recall_RF  Max_Recall\n",
       "0   positive   0.026188    0.200365   0.034714   0.166870    0.200365\n",
       "1   negative   0.299949    0.468892   0.250379   0.405665    0.468892\n",
       "2    neutral   0.341020    0.439902   0.303983   0.350804    0.439902"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = df_NB.Categories\n",
    "df_rec_NB  =df_NB.Recall_NB\n",
    "df_rec_SVC  = df_SVC.Recall_SVC\n",
    "df_rec_LR  = df_LR.Recall_LR\n",
    "df_rec_RF  = df_RF.Recall_RF\n",
    "\n",
    "df_rec = pd.DataFrame(columns = ['Categories', 'Recall_NB', 'Recall_SVC', \n",
    "                                   'Recall_LR', 'Recall_RF','Max_Recall'])\n",
    "df_rec.Categories = df_NB.Categories\n",
    "df_rec.Recall_NB = df_NB.Recall_NB\n",
    "df_rec.Recall_SVC  = df_SVC.Recall_SVC\n",
    "df_rec.Recall_LR  = df_LR.Recall_LR\n",
    "df_rec.Recall_RF = df_RF.Recall_RF\n",
    "df_rec.Max_Recall = df_rec.max(axis=1)\n",
    "df_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>F1_NB</th>\n",
       "      <th>F1_SVC</th>\n",
       "      <th>F1_LR</th>\n",
       "      <th>F1_RF</th>\n",
       "      <th>Max_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.050529</td>\n",
       "      <td>0.287713</td>\n",
       "      <td>0.066628</td>\n",
       "      <td>0.246071</td>\n",
       "      <td>0.287713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.429710</td>\n",
       "      <td>0.551293</td>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.497364</td>\n",
       "      <td>0.551293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.459294</td>\n",
       "      <td>0.509820</td>\n",
       "      <td>0.421818</td>\n",
       "      <td>0.447017</td>\n",
       "      <td>0.509820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categories     F1_NB    F1_SVC     F1_LR     F1_RF    Max_F1\n",
       "0   positive  0.050529  0.287713  0.066628  0.246071  0.287713\n",
       "1   negative  0.429710  0.551293  0.379747  0.497364  0.551293\n",
       "2    neutral  0.459294  0.509820  0.421818  0.447017  0.509820"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = df_NB.Categories\n",
    "df_f1_NB  =df_NB.F1_NB\n",
    "df_f1_SVC  = df_SVC.F1_SVC\n",
    "df_f1_LR  = df_LR.F1_LR\n",
    "df_f1_RF  = df_RF.F1_RF\n",
    "\n",
    "df_f1 = pd.DataFrame(columns = ['Categories', 'F1_NB', 'F1_SVC', \n",
    "                                   'F1_LR', 'F1_RF','Max_F1'])\n",
    "df_f1.Categories = df_NB.Categories\n",
    "df_f1.F1_NB = df_NB.F1_NB\n",
    "df_f1.F1_SVC  = df_SVC.F1_SVC\n",
    "df_f1.F1_LR  = df_LR.F1_LR\n",
    "df_f1.F1_RF  = df_RF.F1_RF\n",
    "df_f1.Max_F1 = df_f1.max(axis=1)\n",
    "df_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyperparameters for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "Best loss: squared_hinge\n",
      "Best C: 1000 \n",
      "\n",
      "negative\n",
      "Best loss: squared_hinge\n",
      "Best C: 10000 \n",
      "\n",
      "neutral\n",
      "Best loss: hinge\n",
      "Best C: 10000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "featurizer = TfidfVectorizer(stop_words='english',binary=False,max_df=50,min_df=1)\n",
    "X = featurizer.fit_transform(df_train.tweet)\n",
    "\n",
    "clf_SVC = LinearSVC(random_state=42)\n",
    "\n",
    "\n",
    "loss = ['hinge', 'squared_hinge']\n",
    "#kernel = ['linear', 'rbf', 'poly']\n",
    "C = [1, 10, 100, 1000, 10000]\n",
    "\n",
    "\n",
    "    # Create hyperparameter options\n",
    "hyperparameters = dict(C=C, loss=loss)\n",
    "\n",
    "\n",
    "     # Create grid search using 5-fold cross validation\n",
    "clf_tune = GridSearchCV(clf_SVC, hyperparameters, cv=5, scoring='recall')               \n",
    "\n",
    "for category in categories:\n",
    "    # Fit grid search\n",
    "    best_model = clf_tune.fit(X, df_train[category])                \n",
    "                \n",
    "    # View best hyperparameters\n",
    "    print(category)\n",
    "    #print('Best kernel:', best_model.best_estimator_.get_params()['kernel'])\n",
    "    print('Best loss:', best_model.best_estimator_.get_params()['loss'])\n",
    "    print('Best C:', best_model.best_estimator_.get_params()['C'],'\\n')         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the tuned LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Precision_SVC</th>\n",
       "      <th>Recall_SVC</th>\n",
       "      <th>F1_SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>[[3984, 855], [1113, 529]]</td>\n",
       "      <td>0.382225</td>\n",
       "      <td>0.322168</td>\n",
       "      <td>0.349636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>[[3526, 978], [880, 1097]]</td>\n",
       "      <td>0.528675</td>\n",
       "      <td>0.554881</td>\n",
       "      <td>0.541461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[[2263, 1356], [1297, 1565]]</td>\n",
       "      <td>0.535775</td>\n",
       "      <td>0.546820</td>\n",
       "      <td>0.541242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categories              Confusion Matrix  Precision_SVC  Recall_SVC  \\\n",
       "0   positive    [[3984, 855], [1113, 529]]       0.382225    0.322168   \n",
       "1   negative    [[3526, 978], [880, 1097]]       0.528675    0.554881   \n",
       "2    neutral  [[2263, 1356], [1297, 1565]]       0.535775    0.546820   \n",
       "\n",
       "     F1_SVC  \n",
       "0  0.349636  \n",
       "1  0.541461  \n",
       "2  0.541242  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizer = TfidfVectorizer(stop_words='english',binary=False,max_df=50,min_df=1, ngram_range=(1, 1))\n",
    "X = featurizer.fit_transform(df_train.tweet)\n",
    "\n",
    "clf_SVC = LinearSVC(random_state=42)\n",
    "\n",
    "\n",
    "#Prediciton with NB\n",
    "conmatrxSVC = []\n",
    "precisionSVC = []\n",
    "recallSVC = []\n",
    "f1SVC = []\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "    if category == 'positive':\n",
    "        clf_tunedSVC = LinearSVC(random_state=42, loss='squared_hinge', C=1000)\n",
    "    if category == 'negative':\n",
    "        clf_tunedSVC = LinearSVC(random_state=42, loss='squared_hinge', C=10000)\n",
    "    if category == 'neutral':\n",
    "        clf_tunedSVC = LinearSVC(random_state=42, loss='hinge', C=10000)\n",
    "    \n",
    "    y_train_pred = cross_val_predict(clf_tunedSVC, X, df_train[category], cv=5)\n",
    "\n",
    "    \n",
    "    cmSVC = confusion_matrix(df_train[category], y_train_pred)\n",
    "    conmatrxSVC.append(cmSVC)\n",
    "    precSVC = precision_score(df_train[category], y_train_pred)    \n",
    "    precisionSVC.append(precSVC)\n",
    "    recSVC = recall_score(df_train[category], y_train_pred)\n",
    "    recallSVC.append(recSVC)\n",
    "    fSVC = f1_score(df_train[category], y_train_pred)\n",
    "    f1SVC.append(fSVC)\n",
    "\n",
    "    \n",
    "dictSVC = {'Categories':categories, 'Confusion Matrix':conmatrxSVC, 'Precision_SVC':precisionSVC, \n",
    "           'Recall_SVC':recallSVC, 'F1_SVC':f1SVC}\n",
    "df_SVC = pd.DataFrame(dictSVC) \n",
    "#df_NB.to_csv('Results_NB_tweets.csv')\n",
    "\n",
    "df_tunedSVC_tweets = df_SVC[df_SVC['Precision_SVC'] >= 0]\n",
    " \n",
    "df_tunedSVC_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune hyperparameters for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "Best n_estimators: 16 \n",
      "\n",
      "negative\n",
      "Best n_estimators: 100 \n",
      "\n",
      "neutral\n",
      "Best n_estimators: 200 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english',binary=False,max_df=50, ngram_range=(1, 1),\n",
    "                                     min_df=1,strip_accents='unicode',max_features=200)\n",
    "\n",
    "X = vectorizer.fit_transform(df_train.tweet)\n",
    "\n",
    "\n",
    "clf_RF2 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
    "#max_depth = [1, 32, 32]\n",
    "\n",
    "    # Create hyperparameter options\n",
    "hyperparameters = dict(n_estimators=n_estimators)\n",
    "\n",
    "\n",
    "     # Create grid search using 5-fold cross validation\n",
    "clf_tune = GridSearchCV(clf_RF2, hyperparameters, cv=5, scoring='recall')               \n",
    "\n",
    "for category in categories:\n",
    "    # Fit grid search\n",
    "    best_model = clf_tune.fit(X, df_train[category])                \n",
    "                \n",
    "    # View best hyperparameters\n",
    "    print(category)\n",
    "    #print('Best max_depth:', best_model.best_estimator_.get_params()['max_depth'])\n",
    "    print('Best n_estimators:', best_model.best_estimator_.get_params()['n_estimators'],'\\n')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the tuned RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Precision_RF</th>\n",
       "      <th>Recall_RF</th>\n",
       "      <th>F1_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>[[4458, 381], [1389, 253]]</td>\n",
       "      <td>0.399054</td>\n",
       "      <td>0.15408</td>\n",
       "      <td>0.222320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>[[4005, 499], [1212, 765]]</td>\n",
       "      <td>0.605222</td>\n",
       "      <td>0.38695</td>\n",
       "      <td>0.472077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[[3168, 451], [2054, 808]]</td>\n",
       "      <td>0.641779</td>\n",
       "      <td>0.28232</td>\n",
       "      <td>0.392138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categories            Confusion Matrix  Precision_RF  Recall_RF     F1_RF\n",
       "0   positive  [[4458, 381], [1389, 253]]      0.399054    0.15408  0.222320\n",
       "1   negative  [[4005, 499], [1212, 765]]      0.605222    0.38695  0.472077\n",
       "2    neutral  [[3168, 451], [2054, 808]]      0.641779    0.28232  0.392138"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english',binary=False,max_df=50, ngram_range=(1, 1),\n",
    "                                     min_df=1,strip_accents='unicode',max_features=200)\n",
    "\n",
    "X = vectorizer.fit_transform(df_train.tweet)\n",
    "\n",
    "\n",
    "#Prediciton with NB\n",
    "conmatrxRF = []\n",
    "precisionRF = []\n",
    "recallRF = []\n",
    "f1RF = []\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "    if category == 'positive':\n",
    "        clf_tunedRF = RandomForestClassifier(random_state=42, n_estimators=16)\n",
    "    if category == 'negative':\n",
    "        clf_tunedRF = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    if category == 'neutral':\n",
    "        clf_tunedRF= RandomForestClassifier(random_state=42, n_estimators=200)\n",
    "    \n",
    "    y_train_pred = cross_val_predict(clf_tunedRF, X, df_train[category], cv=5)\n",
    "\n",
    "    \n",
    "    cmRF = confusion_matrix(df_train[category], y_train_pred)\n",
    "    conmatrxRF.append(cmRF)\n",
    "    precRF = precision_score(df_train[category], y_train_pred)    \n",
    "    precisionRF.append(precRF)\n",
    "    recRF = recall_score(df_train[category], y_train_pred)\n",
    "    recallRF.append(recRF)\n",
    "    fRF = f1_score(df_train[category], y_train_pred)\n",
    "    f1RF.append(fRF)\n",
    "\n",
    "    \n",
    "dictRF = {'Categories':categories, 'Confusion Matrix':conmatrxRF, 'Precision_RF':precisionRF, \n",
    "           'Recall_RF':recallRF, 'F1_RF':f1RF}\n",
    "df_RF = pd.DataFrame(dictRF) \n",
    "#df_NB.to_csv('Results_NB_tweets.csv')\n",
    "\n",
    "df_tunedRF_tweets = df_RF[df_RF['Precision_RF'] >= 0]\n",
    " \n",
    "df_tunedRF_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyperparameters for LR\n",
    "\n",
    "The ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers support only l2 penalties. I will first leave out the solver and check for the best penalty. The I will choose the solvers that best run with that penalty.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "Best penalty: l2\n",
      "Best C: 206.913808111479 \n",
      "\n",
      "negative\n",
      "Best penalty: l1\n",
      "Best C: 206.913808111479 \n",
      "\n",
      "neutral\n",
      "Best penalty: l2\n",
      "Best C: 11.288378916846883 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#silence warnings about default solver changing to 'lbfgs'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english',binary=False,max_df=50, ngram_range=(1, 1),\n",
    "                                     min_df=1,strip_accents='unicode',max_features=200)\n",
    "\n",
    "X = vectorizer.fit_transform(df_train.tweet)\n",
    "\n",
    "\n",
    "\n",
    "clf_LR2 = LogisticRegression(random_state=42)\n",
    "\n",
    "#The ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers support only l2 penalties.\n",
    "\n",
    "    # Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "    # Create regularization hyperparameter space\n",
    "C = np.logspace(-4, 4, 20)\n",
    "\n",
    "#solver = ['liblinear', 'sag', 'newton-cg', 'saga', 'lbfgs']\n",
    "\n",
    "\n",
    "    # Create hyperparameter options\n",
    "hyperparameters = dict(penalty = penalty, C=C)\n",
    "\n",
    "\n",
    "     # Create grid search using 5-fold cross validation\n",
    "clf_tune = GridSearchCV(clf_LR2, hyperparameters, cv=5, verbose=0, scoring='f1')               \n",
    "\n",
    "for category in categories:\n",
    "    # Fit grid search\n",
    "    best_model = clf_tune.fit(X, df_train[category])                \n",
    "                \n",
    "    # View best hyperparameters\n",
    "    print(category)\n",
    "    print('Best penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "    print('Best C:', best_model.best_estimator_.get_params()['C'],'\\n')         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "Best solver: sag\n",
      "Best C: 545.5594781168514 \n",
      "\n",
      "negative\n",
      "Best solver: lbfgs\n",
      "Best C: 545.5594781168514 \n",
      "\n",
      "neutral\n",
      "Best solver: saga\n",
      "Best C: 11.288378916846883 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english',binary=False,max_df=50, ngram_range=(1, 1),\n",
    "                                     min_df=1,strip_accents='unicode',max_features=200)\n",
    "X = vectorizer.fit_transform(df_train.tweet)\n",
    "\n",
    "\n",
    "clf_LR3 = LogisticRegression()\n",
    "\n",
    "#The ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers support only l2 penalties.\n",
    "\n",
    "    # Create regularization penalty space\n",
    "penalty = ['l2']\n",
    "\n",
    "    # Create regularization hyperparameter space\n",
    "C = np.logspace(-4, 4, 20)\n",
    "\n",
    "solver = ['liblinear', 'sag', 'newton-cg', 'saga', 'lbfgs']\n",
    "\n",
    "\n",
    "    # Create hyperparameter options\n",
    "hyperparameters = dict(solver = solver, C=C)\n",
    "\n",
    "\n",
    "     # Create grid search using 5-fold cross validation\n",
    "clf_tuneLR = GridSearchCV(clf_LR3, hyperparameters, cv=5, verbose=0, scoring='f1')               \n",
    "\n",
    "for category in categories:\n",
    "    # Fit grid search\n",
    "    best_model = clf_tuneLR.fit(X, df_train[category])                \n",
    "                \n",
    "    # View best hyperparameters\n",
    "    print(category)\n",
    "    print('Best solver:', best_model.best_estimator_.get_params()['solver'])\n",
    "    print('Best C:', best_model.best_estimator_.get_params()['C'],'\\n')         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, we have a different combination for each label. I will run each separately and examine the differences before predicting on the rately and examine the differences before predicting on the unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Precision_LR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>[[4546, 293], [1423, 219]]</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>0.133374</td>\n",
       "      <td>0.203343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>[[4154, 350], [1307, 670]]</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.338897</td>\n",
       "      <td>0.447114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[[3190, 429], [2062, 800]]</td>\n",
       "      <td>0.650936</td>\n",
       "      <td>0.279525</td>\n",
       "      <td>0.391102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Categories            Confusion Matrix  Precision_LR    Recall        F1\n",
       "0   positive  [[4546, 293], [1423, 219]]      0.427734  0.133374  0.203343\n",
       "1   negative  [[4154, 350], [1307, 670]]      0.656863  0.338897  0.447114\n",
       "2    neutral  [[3190, 429], [2062, 800]]      0.650936  0.279525  0.391102"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hyperpos = ['C=0.23357214690901212']\n",
    "#hyperneg = ['penalty=l2, C=0.08858667904100823']\n",
    "#hyperneut = [\"penalty=l2, C=0.03359818286283781, solver='sag'\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Prediciton with NB\n",
    "conmatrxLR = []\n",
    "precisionLR = []\n",
    "recallLR = []\n",
    "f1LR = []\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "    if category == 'positive':\n",
    "        clf_tuned = LogisticRegression(penalty='l2',C=545.5594781168514,  solver='sag')\n",
    "    if category == 'negative':\n",
    "        clf_tuned = LogisticRegression(penalty='l1', C=206.913808111479, solver='liblinear')\n",
    "    if category == 'neutral':\n",
    "        clf_tuned = LogisticRegression(penalty='l2', C=11.288378916846883, solver='saga')\n",
    "    \n",
    "    y_train_pred = cross_val_predict(clf_tuned, X, df_train[category], cv=5)\n",
    "    \n",
    "    cmLR = confusion_matrix(df_train[category], y_train_pred)\n",
    "    conmatrxLR.append(cmLR)\n",
    "    precLR = precision_score(df_train[category], y_train_pred)    \n",
    "    precisionLR.append(precLR)\n",
    "    recLR = recall_score(df_train[category], y_train_pred)\n",
    "    recallLR.append(recLR)\n",
    "    fLR = f1_score(df_train[category], y_train_pred)\n",
    "    f1LR.append(fLR)\n",
    "\n",
    "dictLR = {'Categories':categories, 'Confusion Matrix':conmatrxLR, 'Precision_LR':precisionLR, \n",
    "           'Recall':recallLR, 'F1':f1LR}\n",
    "df_LR = pd.DataFrame(dictLR) \n",
    "#df_NB.to_csv('Results_NB_tweets.csv')\n",
    "\n",
    "df_tunedLR_tweets = df_LR[df_LR['Precision_LR'] >= 0]\n",
    " \n",
    "\n",
    "df_tunedLR_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
